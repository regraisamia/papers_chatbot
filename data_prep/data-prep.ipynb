{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebafcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"0704.0001\",\"submitter\":\"Pavel Nadolsky\",\"authors\":\"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\"title\":\"Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies\",\"comments\":\"37 pages, 15 figures; published version\",\"journal-ref\":\"Phys.Rev.D76:013009,2007\",\"doi\":\"10.1103/PhysRevD.76.013009\",\"report-no\":\"ANL-HEP-PR-07-12\",\"categories\":\"hep-ph\",\"license\":null,\"abstract\":\"  A fully differential calculation in perturbative quantum chromodynamics is\\n\n",
      "{\"id\":\"0704.0002\",\"submitter\":\"Louis Theran\",\"authors\":\"Ileana Streinu and Louis Theran\",\"title\":\"Sparsity-certifying Graph Decompositions\",\"comments\":\"To appear in Graphs and Combinatorics\",\"journal-ref\":null,\"doi\":null,\"report-no\":null,\"categories\":\"math.CO cs.CG\",\"license\":\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\",\"abstract\":\"  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\\n",
      "{\"id\":\"0704.0003\",\"submitter\":\"Hongjun Pan\",\"authors\":\"Hongjun Pan\",\"title\":\"The evolution of the Earth-Moon system based on the dark matter field\\n  fluid model\",\"comments\":\"23 pages, 3 figures\",\"journal-ref\":null,\"doi\":null,\"report-no\":null,\"categories\":\"physics.gen-ph\",\"license\":null,\"abstract\":\"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior\n"
     ]
    }
   ],
   "source": [
    "def preview_file(filename, n=3):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for _ in range(n):\n",
    "            line = f.readline()\n",
    "            print(line[:500])  # affiche 500 premiers caractères\n",
    "\n",
    "preview_file(\"arxiv-metadata-oai-snapshot.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb1c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des articles par année : {2020: 700, 2021: 700, 2022: 700, 2023: 700, 2024: 200, 2025: 0}\n",
      "Nombre total d'articles : 3000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_year(article_id):\n",
    "    # id au format YYMM.XXXX, on convertit YY en 2000+YY si < 50 sinon 1900+YY\n",
    "    match = re.match(r'(\\d{2})\\d{2}\\.\\d+', article_id)\n",
    "    if match:\n",
    "        yy = int(match.group(1))\n",
    "        year = 2000 + yy if yy < 50 else 1900 + yy\n",
    "        return year\n",
    "    return None\n",
    "\n",
    "def process_arxiv_file_balanced(input_filepath, min_year=2020, max_year=2025, max_articles=3000, max_per_year=700):\n",
    "    articles = []\n",
    "    authors_list = []\n",
    "    counts_per_year = {year: 0 for year in range(min_year, max_year + 1)}\n",
    "    total_count = 0\n",
    "\n",
    "    with open(input_filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                article = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            year = extract_year(article.get('id', ''))\n",
    "            if year is None or year < min_year or year > max_year:\n",
    "                continue\n",
    "\n",
    "            cats = article.get('categories', '')\n",
    "            if not any(c.strip().startswith('cs') for c in cats.split()):\n",
    "                continue\n",
    "\n",
    "            # Stopper la collecte si quota max atteint pour cette année\n",
    "            if counts_per_year[year] >= max_per_year:\n",
    "                continue\n",
    "\n",
    "            # Nettoyage basique des champs texte\n",
    "            for field in ['title', 'abstract', 'comments', 'journal-ref', 'doi', 'submitter']:\n",
    "                if field in article and article[field]:\n",
    "                    article[field] = article[field].replace('\\n', ' ').strip()\n",
    "                else:\n",
    "                    article[field] = ''\n",
    "\n",
    "            article['year'] = year\n",
    "            article['categories'] = cats\n",
    "\n",
    "            articles.append(article)\n",
    "            counts_per_year[year] += 1\n",
    "            total_count += 1\n",
    "\n",
    "            authors_str = article.get('authors', '')\n",
    "            authors = [a.strip() for a in authors_str.split(',') if a.strip()]\n",
    "            for auth in authors:\n",
    "                authors_list.append({\n",
    "                    'article_id': article['id'],\n",
    "                    'author_name': auth\n",
    "                })\n",
    "\n",
    "            # Arrêter si on a atteint le max total d’articles\n",
    "            if total_count >= max_articles:\n",
    "                break\n",
    "\n",
    "            # Arrêter si toutes les années ont atteint leur quota max\n",
    "            if all(count >= max_per_year for count in counts_per_year.values()):\n",
    "                break\n",
    "\n",
    "    df_articles = pd.DataFrame(articles)\n",
    "    df_authors = pd.DataFrame(authors_list).drop_duplicates()\n",
    "\n",
    "    print(\"Répartition des articles par année :\", counts_per_year)\n",
    "    print(\"Nombre total d'articles :\", total_count)\n",
    "\n",
    "    return df_articles, df_authors\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "df_articles, df_authors = process_arxiv_file_balanced(\"arxiv-metadata-oai-snapshot.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43b069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Sauvegarder résultats\n",
    "df_articles.to_csv('arxiv_cs_2020_2025_articles.csv', index=False, encoding='utf-8-sig')\n",
    "df_authors.to_csv('arxiv_cs_2020_2025_authors.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d473b",
   "metadata": {},
   "source": [
    "pretraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321bd84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aperçu des articles ===\n",
      "           id       submitter  \\\n",
      "0  2001.00001   Maria Mannone   \n",
      "1  2001.00003  Chengyue Jiang   \n",
      "2  2001.00004  Rakesh Mohanty   \n",
      "\n",
      "                                             authors  \\\n",
      "0  Maria Mannone, Federico Favali, Balandino Di D...   \n",
      "1  Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Sha...   \n",
      "2  Rakesh Mohanty, Debasis Dwibedy, Shreeya Swaga...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Quantum GestART: Identifying and Applying Corr...   \n",
      "1                        Learning Numeral Embeddings   \n",
      "2  New Competitive Analysis Results of Online Lis...   \n",
      "\n",
      "                                            comments  \\\n",
      "0  Accepted for publication, Journal of Mathemati...   \n",
      "1                                                NaN   \n",
      "2  9 pages, In Proceeding of the 14th Annual ADMA...   \n",
      "\n",
      "                              journal-ref                            doi  \\\n",
      "0  Journal of Mathematics and Music, 2020  10.1080/17459737.2020.1726691   \n",
      "1                                     NaN                            NaN   \n",
      "2                                     NaN                            NaN   \n",
      "\n",
      "  report-no     categories                                            license  \\\n",
      "0       NaN  math.HO cs.MM  http://creativecommons.org/licenses/by-nc-sa/4.0/   \n",
      "1       NaN          cs.CL  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2       NaN          cs.DS  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Mathematics can help analyze the arts and insp...   \n",
      "1  Word embedding is an essential building block ...   \n",
      "2  Online algorithm has been an emerging area of ...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Mon, 16 Dec 201...  2020-03-25   \n",
      "1  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-14   \n",
      "2  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-03   \n",
      "\n",
      "                                      authors_parsed  year  \n",
      "0  [['Mannone', 'Maria', ''], ['Favali', 'Federic...  2020  \n",
      "1  [['Jiang', 'Chengyue', ''], ['Nian', 'Zhonglin...  2020  \n",
      "2  [['Mohanty', 'Rakesh', ''], ['Dwibedy', 'Debas...  2020  \n",
      "\n",
      "Colonnes articles: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed', 'year']\n",
      "\n",
      "Types articles:\n",
      "id                float64\n",
      "submitter          object\n",
      "authors            object\n",
      "title              object\n",
      "comments           object\n",
      "journal-ref        object\n",
      "doi                object\n",
      "report-no          object\n",
      "categories         object\n",
      "license            object\n",
      "abstract           object\n",
      "versions           object\n",
      "update_date        object\n",
      "authors_parsed     object\n",
      "year                int64\n",
      "dtype: object\n",
      "\n",
      "Nombre d'articles : 3000\n",
      "Articles par année:\n",
      "2020    700\n",
      "2021    700\n",
      "2022    700\n",
      "2023    700\n",
      "2024    200\n",
      "Name: year, dtype: int64\n",
      "\n",
      "Catégories (extraits):\n",
      "cs.CV            213\n",
      "cs.CL             97\n",
      "math.NA cs.NA     94\n",
      "cs.LG             80\n",
      "eess.SY cs.SY     68\n",
      "eess.IV cs.CV     56\n",
      "cs.LG cs.AI       54\n",
      "cs.IT math.IT     54\n",
      "cs.RO             54\n",
      "cs.CR             53\n",
      "Name: categories, dtype: int64\n",
      "\n",
      "Valeurs manquantes par colonne (articles):\n",
      "id                   0\n",
      "submitter            0\n",
      "authors              0\n",
      "title                0\n",
      "comments          1246\n",
      "journal-ref       2587\n",
      "doi               2365\n",
      "report-no         2979\n",
      "categories           0\n",
      "license              0\n",
      "abstract             0\n",
      "versions             0\n",
      "update_date          0\n",
      "authors_parsed       0\n",
      "year                 0\n",
      "dtype: int64\n",
      "\n",
      "=== Aperçu des auteurs ===\n",
      "   article_id          author_name\n",
      "0  2001.00001        Maria Mannone\n",
      "1  2001.00001      Federico Favali\n",
      "2  2001.00001  Balandino Di Donato\n",
      "\n",
      "Colonnes auteurs: ['article_id', 'author_name']\n",
      "\n",
      "Types auteurs:\n",
      "article_id     float64\n",
      "author_name     object\n",
      "dtype: object\n",
      "\n",
      "Nombre total d'auteurs extraits: 10650\n",
      "Nombre d'auteurs uniques : 9795\n",
      "\n",
      "Valeurs manquantes par colonne (auteurs):\n",
      "article_id     0\n",
      "author_name    0\n",
      "dtype: int64\n",
      "\n",
      "Doublons dans auteurs (article_id + author_name): 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemins vers les fichiers CSV\n",
    "ARTICLES_FILE = \"arxiv_cs_2020_2025_articles.csv\"\n",
    "AUTHORS_FILE = \"arxiv_cs_2020_2025_authors.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_articles = pd.read_csv(ARTICLES_FILE, encoding='utf-8-sig')\n",
    "df_authors = pd.read_csv(AUTHORS_FILE, encoding='utf-8-sig')\n",
    "\n",
    "print(\"=== Aperçu des articles ===\")\n",
    "print(df_articles.head(3))\n",
    "print(\"\\nColonnes articles:\", df_articles.columns.tolist())\n",
    "print(\"\\nTypes articles:\")\n",
    "print(df_articles.dtypes)\n",
    "\n",
    "print(\"\\nNombre d'articles :\", len(df_articles))\n",
    "print(\"Articles par année:\")\n",
    "print(df_articles['year'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCatégories (extraits):\")\n",
    "print(df_articles['categories'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne (articles):\")\n",
    "print(df_articles.isna().sum())\n",
    "\n",
    "print(\"\\n=== Aperçu des auteurs ===\")\n",
    "print(df_authors.head(3))\n",
    "print(\"\\nColonnes auteurs:\", df_authors.columns.tolist())\n",
    "print(\"\\nTypes auteurs:\")\n",
    "print(df_authors.dtypes)\n",
    "\n",
    "print(\"\\nNombre total d'auteurs extraits:\", len(df_authors))\n",
    "print(\"Nombre d'auteurs uniques :\", df_authors['author_name'].nunique())\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne (auteurs):\")\n",
    "print(df_authors.isna().sum())\n",
    "\n",
    "print(\"\\nDoublons dans auteurs (article_id + author_name):\", df_authors.duplicated(subset=['article_id', 'author_name']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e2c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nettoyage terminé.\n",
      "Articles nettoyés: 3000\n",
      "Auteurs extraits (lignes): 4320\n",
      "Auteurs uniques: 4189\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Fichier source\n",
    "ARTICLES_FILE = \"arxiv_cs_2020_2025_articles.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_articles = pd.read_csv(ARTICLES_FILE, encoding='utf-8-sig')\n",
    "\n",
    "# 1. Nettoyage général des articles ----------------------\n",
    "\n",
    "# Suppression doublons selon id\n",
    "df_articles = df_articles.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "\n",
    "# Suppression colonne 'comments' trop incomplète\n",
    "if 'comments' in df_articles.columns:\n",
    "    df_articles.drop(columns=['comments'], inplace=True)\n",
    "\n",
    "# Colonnes texte où remplacer NaN par chaîne vide\n",
    "text_cols = ['journal-ref', 'doi', 'report-no', 'license', 'abstract', 'title', 'categories', 'submitter']\n",
    "for col in text_cols:\n",
    "    if col in df_articles.columns:\n",
    "        df_articles[col] = df_articles[col].fillna('')\n",
    "\n",
    "# Nettoyage retours à la ligne et espaces dans 'title' et 'abstract'\n",
    "for col in ['title', 'abstract']:\n",
    "    df_articles[col] = df_articles[col].str.replace('\\n', ' ', regex=True).str.strip()\n",
    "\n",
    "# 2. Extraction + nettoyage auteurs ----------------------\n",
    "\n",
    "def clean_latex(name):\n",
    "    \"\"\"Simplifie certains accents LaTeX courants dans les noms.\"\"\"\n",
    "    name = name.replace(\"\\\\'\", \"'\")      # accent aigu\n",
    "    name = re.sub(r\"\\\\v\\{([a-zA-Z])\\}\", r\"\\1\", name)  # accent caron\n",
    "    name = name.replace(\"\\\\\\\"\", '\"')     # guillemets\n",
    "    name = name.replace(\"~\", \" \")        # espace insécable\n",
    "    return name.strip()\n",
    "\n",
    "def split_authors(authors_str):\n",
    "    \"\"\"Sépare la chaîne 'authors' sur ' and ' en liste d'auteurs nettoyés.\"\"\"\n",
    "    if pd.isna(authors_str) or authors_str.strip() == '':\n",
    "        return []\n",
    "    authors = authors_str.split(' and ')\n",
    "    return [clean_latex(a.strip()) for a in authors]\n",
    "\n",
    "# Extraire auteurs par article et exploser en lignes séparées\n",
    "df_authors = df_articles[['id', 'authors']].copy()\n",
    "df_authors['author_name'] = df_authors['authors'].apply(split_authors)\n",
    "df_authors = df_authors.explode('author_name').reset_index(drop=True)\n",
    "df_authors['author_name'] = df_authors['author_name'].fillna('').str.strip()\n",
    "\n",
    "# Supprimer doublons article+auteur\n",
    "df_authors = df_authors.drop_duplicates(subset=['id', 'author_name']).reset_index(drop=True)\n",
    "\n",
    "# Renommer colonne id pour cohérence\n",
    "df_authors.rename(columns={'id': 'article_id'}, inplace=True)\n",
    "\n",
    "# 3. Sauvegarde ------------------------------------------\n",
    "\n",
    "df_articles.to_csv(\"arxiv_cs_2020_2025_articles_clean.csv\", index=False, encoding='utf-8-sig')\n",
    "df_authors.to_csv(\"arxiv_cs_2020_2025_authors_clean.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Nettoyage terminé.\")\n",
    "print(f\"Articles nettoyés: {len(df_articles)}\")\n",
    "print(f\"Auteurs extraits (lignes): {len(df_authors)}\")\n",
    "print(f\"Auteurs uniques: {df_authors['author_name'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ce9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  count\n",
      "0  2020    700\n",
      "1  2021    700\n",
      "2  2022    700\n",
      "3  2023    700\n",
      "4  2024    200\n"
     ]
    }
   ],
   "source": [
    "articles_par_year = df_articles.groupby('year').size().reset_index(name='count')\n",
    "print(articles_par_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10208da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aperçu des articles ===\n",
      "           id       submitter  \\\n",
      "0  2001.00001   Maria Mannone   \n",
      "1  2001.00003  Chengyue Jiang   \n",
      "2  2001.00004  Rakesh Mohanty   \n",
      "\n",
      "                                             authors  \\\n",
      "0  Maria Mannone, Federico Favali, Balandino Di D...   \n",
      "1  Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Sha...   \n",
      "2  Rakesh Mohanty, Debasis Dwibedy, Shreeya Swaga...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Quantum GestART: Identifying and Applying Corr...   \n",
      "1                        Learning Numeral Embeddings   \n",
      "2  New Competitive Analysis Results of Online Lis...   \n",
      "\n",
      "                              journal-ref                            doi  \\\n",
      "0  Journal of Mathematics and Music, 2020  10.1080/17459737.2020.1726691   \n",
      "1                                     NaN                            NaN   \n",
      "2                                     NaN                            NaN   \n",
      "\n",
      "  report-no     categories                                            license  \\\n",
      "0       NaN  math.HO cs.MM  http://creativecommons.org/licenses/by-nc-sa/4.0/   \n",
      "1       NaN          cs.CL  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2       NaN          cs.DS  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Mathematics can help analyze the arts and insp...   \n",
      "1  Word embedding is an essential building block ...   \n",
      "2  Online algorithm has been an emerging area of ...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Mon, 16 Dec 201...  2020-03-25   \n",
      "1  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-14   \n",
      "2  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-03   \n",
      "\n",
      "                                      authors_parsed  year  \n",
      "0  [['Mannone', 'Maria', ''], ['Favali', 'Federic...  2020  \n",
      "1  [['Jiang', 'Chengyue', ''], ['Nian', 'Zhonglin...  2020  \n",
      "2  [['Mohanty', 'Rakesh', ''], ['Dwibedy', 'Debas...  2020  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ARTICLES_FILE = \"arxiv_cs_2020_2025_articles_clean.csv\"\n",
    "AUTHORS_FILE = \"arxiv_cs_2020_2025_authors_clean.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_articles = pd.read_csv(ARTICLES_FILE, encoding='utf-8-sig')\n",
    "df_authors = pd.read_csv(AUTHORS_FILE, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "print(\"=== Aperçu des articles ===\")\n",
    "print(df_articles.head(3))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869082d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a033ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aperçu des auteurs === \n",
      "   article_id                                            authors  \\\n",
      "0  2001.00001  Maria Mannone, Federico Favali, Balandino Di D...   \n",
      "1  2001.00003  Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Sha...   \n",
      "2  2001.00004  Rakesh Mohanty, Debasis Dwibedy, Shreeya Swaga...   \n",
      "\n",
      "                                         author_name  \n",
      "0  Maria Mannone, Federico Favali, Balandino Di D...  \n",
      "1  Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Sha...  \n",
      "2  Rakesh Mohanty, Debasis Dwibedy, Shreeya Swaga...  \n"
     ]
    }
   ],
   "source": [
    "print(\"aperçu des auteurs === \")    \n",
    "print(df_authors.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLES_FILE = \"arxiv_cs_2020_2025_articles_clean.csv\"\n",
    "AUTHORS_FILE = \"arxiv_cs_2020_2025_authors_clean.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_articles = pd.read_csv(ARTICLES_FILE, encoding='utf-8-sig')\n",
    "df_authors = pd.read_csv(AUTHORS_FILE, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f84837ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nettoyage, explosion auteurs et sauvegarde terminés.\n",
      "Nombre de lignes dans le fichier nettoyé : 11967\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier existant\n",
    "df_authors = pd.read_csv(\"arxiv_cs_2020_2025_authors_clean.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Nettoyage et explosion des auteurs\n",
    "df_authors_exp = df_authors[['article_id', 'authors']].copy()\n",
    "\n",
    "# Remplacer \" and \" par \", \" pour uniformiser la séparation\n",
    "df_authors_exp['author_name'] = df_authors_exp['authors'].str.replace(\" and \", \", \")\n",
    "\n",
    "# Split en liste et explode\n",
    "df_authors_exp['author_name'] = df_authors_exp['author_name'].str.split(',')\n",
    "\n",
    "df_authors_exp = df_authors_exp.explode('author_name')\n",
    "\n",
    "# Nettoyer espaces\n",
    "df_authors_exp['author_name'] = df_authors_exp['author_name'].str.strip()\n",
    "\n",
    "# Supprimer colonne 'authors' initiale\n",
    "df_authors_exp = df_authors_exp.drop(columns=['authors'])\n",
    "\n",
    "# Supprimer doublons éventuels\n",
    "df_authors_exp = df_authors_exp.drop_duplicates(subset=['article_id', 'author_name']).reset_index(drop=True)\n",
    "\n",
    "# Sauvegarder dans un nouveau fichier CSV\n",
    "df_authors_exp.to_csv(\"arxiv_cs_2020_2025_authors_clean_expanded.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Nettoyage, explosion auteurs et sauvegarde terminés.\")\n",
    "print(f\"Nombre de lignes dans le fichier nettoyé : {len(df_authors_exp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498efdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id       submitter  \\\n",
      "0  2001.00001   Maria Mannone   \n",
      "1  2001.00003  Chengyue Jiang   \n",
      "2  2001.00004  Rakesh Mohanty   \n",
      "\n",
      "                                             authors  \\\n",
      "0  Maria Mannone, Federico Favali, Balandino Di D...   \n",
      "1  Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Sha...   \n",
      "2  Rakesh Mohanty, Debasis Dwibedy, Shreeya Swaga...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Quantum GestART: Identifying and Applying Corr...   \n",
      "1                        Learning Numeral Embeddings   \n",
      "2  New Competitive Analysis Results of Online Lis...   \n",
      "\n",
      "                              journal-ref                            doi  \\\n",
      "0  Journal of Mathematics and Music, 2020  10.1080/17459737.2020.1726691   \n",
      "1                                     NaN                            NaN   \n",
      "2                                     NaN                            NaN   \n",
      "\n",
      "  report-no     categories                                            license  \\\n",
      "0       NaN  math.HO cs.MM  http://creativecommons.org/licenses/by-nc-sa/4.0/   \n",
      "1       NaN          cs.CL  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2       NaN          cs.DS  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Mathematics can help analyze the arts and insp...   \n",
      "1  Word embedding is an essential building block ...   \n",
      "2  Online algorithm has been an emerging area of ...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Mon, 16 Dec 201...  2020-03-25   \n",
      "1  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-14   \n",
      "2  [{'version': 'v1', 'created': 'Sat, 28 Dec 201...  2020-01-03   \n",
      "\n",
      "                                      authors_parsed  year  \n",
      "0  [['Mannone', 'Maria', ''], ['Favali', 'Federic...  2020  \n",
      "1  [['Jiang', 'Chengyue', ''], ['Nian', 'Zhonglin...  2020  \n",
      "2  [['Mohanty', 'Rakesh', ''], ['Dwibedy', 'Debas...  2020  \n",
      "   article_id          author_name\n",
      "0  2001.00001        Maria Mannone\n",
      "1  2001.00001      Federico Favali\n",
      "2  2001.00001  Balandino Di Donato\n"
     ]
    }
   ],
   "source": [
    "ARTICLES_FILE = \"arxiv_cs_2020_2025_articles_clean.csv\"\n",
    "AUTHORS_FILE = \"arxiv_cs_2020_2025_authors_clean_expanded.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_articles = pd.read_csv(ARTICLES_FILE, encoding='utf-8-sig')\n",
    "df_authors = pd.read_csv(AUTHORS_FILE, encoding='utf-8-sig')\n",
    "\n",
    "print(df_articles.head(3))\n",
    "print(df_authors.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
